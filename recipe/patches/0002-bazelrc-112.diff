From 093c806ba0ffce66048be2f6c632ac715bd85146 Mon Sep 17 00:00:00 2001
From: ngam <67342040+ngam@users.noreply.github.com>
Date: Wed, 22 Jun 2022 20:42:50 +0000
Subject: [PATCH 2/2] cuda

---
 .bazelrc | 12 ++++++------
 1 file changed, 6 insertions(+), 6 deletions(-)

diff --git a/.bazelrc b/.bazelrc
index da136a8d7..d96c90257 100644
--- a/.bazelrc
+++ b/.bazelrc
@@ -56,14 +56,14 @@ build:native_arch_posix --host_copt=-march=native
 
 build:mkl_open_source_only --define=tensorflow_mkldnn_contraction_kernel=1
 
-build:cuda --repo_env TF_NEED_CUDA=1
+build --repo_env TF_NEED_CUDA=1
 # "sm" means we emit only cubin, which is forward compatible within a GPU generation.
 # "compute" means we emit both cubin and PTX, which is larger but also forward compatible to future GPU generations.
-build:cuda --action_env TF_CUDA_COMPUTE_CAPABILITIES="sm_52,sm_60,sm_70,compute_80"
-build:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain
-build:cuda --@local_config_cuda//:enable_cuda
-build:cuda --@org_tensorflow//tensorflow/compiler/xla/python:enable_gpu=true
-build:cuda --define=xla_python_enable_gpu=true
+build --action_env TF_CUDA_COMPUTE_CAPABILITIES="sm_35,sm_50,sm_60,sm_62,sm_70,sm_72,sm_75,sm_80,sm_86,compute_86"
+build --crosstool_top=@local_config_cuda//crosstool:toolchain
+build --@local_config_cuda//:enable_cuda
+build --@org_tensorflow//tensorflow/compiler/xla/python:enable_gpu=true
+build --define=xla_python_enable_gpu=true
 
 build:rocm --crosstool_top=@local_config_rocm//crosstool:toolchain
 build:rocm --define=using_rocm=true --define=using_rocm_hipcc=true
-- 
2.36.1

