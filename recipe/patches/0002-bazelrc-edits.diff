From 093c806ba0ffce66048be2f6c632ac715bd85146 Mon Sep 17 00:00:00 2001
From: ngam <67342040+ngam@users.noreply.github.com>
Date: Wed, 22 Jun 2022 20:42:50 +0000
Subject: [PATCH 2/2] cuda

---
 .bazelrc | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/.bazelrc b/.bazelrc
--- .bazelrc
+++ .bazelrc
@@ -62,17 +62,17 @@
 build:native_arch_posix --host_copt=-march=native
 
 build:mkl_open_source_only --define=tensorflow_mkldnn_contraction_kernel=1
 
-build:cuda --repo_env TF_NEED_CUDA=1
+build --repo_env TF_NEED_CUDA=1
 # "sm" means we emit only cubin, which is forward compatible within a GPU generation.
 # "compute" means we emit both cubin and PTX, which is larger but also forward compatible to future GPU generations.
-build:cuda --action_env TF_CUDA_COMPUTE_CAPABILITIES="sm_52,sm_60,sm_70,compute_80"
-build:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain
-build:cuda --@local_config_cuda//:enable_cuda
-build:cuda --@xla//xla/python:enable_gpu=true
-build:cuda --@xla//xla/python:jax_cuda_pip_rpaths=true
-build:cuda --define=xla_python_enable_gpu=true
+build --action_env TF_CUDA_COMPUTE_CAPABILITIES="sm_35,sm_50,sm_60,sm_62,sm_70,sm_72,sm_75,sm_80,sm_86,compute_86"
+build --crosstool_top=@local_config_cuda//crosstool:toolchain
+build --@local_config_cuda//:enable_cuda
+build --@xla//xla/python:enable_gpu=true
+build --@xla//xla/python:jax_cuda_pip_rpaths=true
+build --define=xla_python_enable_gpu=true
 
 build:rocm --crosstool_top=@local_config_rocm//crosstool:toolchain
 build:rocm --define=using_rocm=true --define=using_rocm_hipcc=true
 build:rocm --@xla//xla/python:enable_gpu=true

-- 
2.36.1
